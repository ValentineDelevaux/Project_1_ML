{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5033210-8301-4857-a975-47dcb365e80a",
   "metadata": {},
   "source": [
    "Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7124d-c406-40d5-847b-d3e4d62b5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155b57-1c16-48d9-bd82-e8a85d37af83",
   "metadata": {},
   "source": [
    "# 1- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca861ce-6071-4920-b488-e54af833ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('dataset_to_release/', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb1e92-7160-4c4f-9916-0fff6018d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapes of x_train :', x_train.shape)\n",
    "print('Shapes of y_train :', y_train.shape)\n",
    "print('Shapes of x_test :', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d75f2-77b1-4b7b-837e-e6067b4e79b0",
   "metadata": {},
   "source": [
    "# 2- Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ff6b3-34f1-4d1b-88b1-6669888f16dc",
   "metadata": {},
   "source": [
    "standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67115d-2a4c-4f74-8c4f-e72bd5994dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis=0)\n",
    "    # Vérifiez si std_x est nul (zéro) avant de diviser\n",
    "    non_zero_std_indices = std_x != 0\n",
    "    x[:, non_zero_std_indices] = x[:, non_zero_std_indices] / std_x[non_zero_std_indices]\n",
    "    return x, non_zero_std_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e992fa-0bc5-4a9f-b112-bae00c389390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enlever premiere colonne x_train car rempli de nan\n",
    "x_train = x_train[:,0:]\n",
    "\n",
    "#Remplacer les nan par la mediane de chaque colonne\n",
    "median = np.nanmedian(x_train, axis = 0)\n",
    "x_train_filled = x_train\n",
    "for col in range(x_train.shape[1]):\n",
    "    x_train_filled[:,col] = np.nan_to_num(x_train[:,col], nan= median[col])\n",
    "\n",
    "x_train_standardized, col_to_keep = standardize_(x_train_filled)\n",
    "\n",
    "#Enlever les colonnes qui ont une std = 0\n",
    "x_train_cleaned = x_train_standardized[:, col_to_keep]\n",
    "print(x_train_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae799f6-603b-43fa-9be3-7d90e764ec53",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af946bb-743a-455a-b8fd-a26ef378b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(x_train_cleaned, rowvar = False)\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f9895-1c31-49eb-8f44-90af16408dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacer la partie triangulaire basse de la matrice par des 0\n",
    "m = np.tril(np.ones(correlation_matrix.shape), k = 0).astype(bool)\n",
    "correlation_matrix[m] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac969971-104f-469a-ae29-bf59b0fc2841",
   "metadata": {},
   "source": [
    "Similar columns deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c8ae0-51d8-493e-85bf-e3a920d8f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des colonnes qui se ressemblent au dessus d'un threshold\n",
    "threshold = 0.8\n",
    "\n",
    "#Creation of a matrix True/False where True == When the correlation is above the treshold\n",
    "mask = np.logical_and(np.abs(correlation_matrix) >= threshold, np.abs(correlation_matrix) < 1)\n",
    "correlated_features = np.where(mask == True)\n",
    "\n",
    "#indices_correlated has the indices of the correlated columns\n",
    "indices_correlated = np.unique(correlated_features[0])\n",
    "\n",
    "#Removes the correlated columns to x_train_cleaned\n",
    "x_train_done = np.delete(x_train_cleaned, indices_correlated, axis = 1)\n",
    "print(x_train_done.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d8adb-546f-49e9-bae5-58ebf8b8e7fc",
   "metadata": {},
   "source": [
    "# 3- Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c5865-ab08-4031-8e4e-7edf78410871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We split x_train in a train part and a validation part\n",
    "seed = 12\n",
    "ratio = 0.8\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Number of elements in y\n",
    "number = y_train.shape[0]\n",
    "\n",
    "index = np.random.permutation(number)\n",
    "\n",
    "#Separate into 2 categories at the split\n",
    "split = int(np.floor(ratio * len(x_train_done)))\n",
    "train = index[:split]\n",
    "test = index[split:]\n",
    "\n",
    "#create the new datasets\n",
    "x_tr = x_train_done[train]\n",
    "y_tr = y_train[train]\n",
    "x_te = x_train_done[test]\n",
    "y_te = y_train[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8cafbe-f1fa-4693-8e5a-a572837ba4a2",
   "metadata": {},
   "source": [
    "# 4- First step w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d91df4-1477-4a53-9227-ceb894641020",
   "metadata": {},
   "source": [
    "### a) Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7e430-7cef-4989-a8bb-2da861feca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "w_initial, loss = least_squares(y_train, x_train_final)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf41ded-2ebf-4460-9326-ae88fdaefa7c",
   "metadata": {},
   "source": [
    "### b) Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7027536-ff7f-4c71-a940-a49b8c2ba4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lambda_ = 0.1\n",
    "w_initial, loss = ridge_regression(y_train, new_data, lambda_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863bac2-5ce6-4e3c-9f9f-6ca400ca8c5f",
   "metadata": {},
   "source": [
    "### c) Looking for good hyperparameters  lambda_ for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469777b-5281-406d-a29f-2f4b4cc46ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.linspace(0,0.5,50)\n",
    "weights = []\n",
    "losses_te = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    w,_ = ridge_regression(y_tr, x_tr, lambda_)\n",
    "    weights.append(w)\n",
    "    loss = compute_loss(y_te, x_te, w)\n",
    "    losses_te.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d38f0-b530-4eb7-94ca-18f989507271",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = losses_te.index(min(losses_te))\n",
    "print('Smallest loss : ',losses_te[best_index])\n",
    "print('Best lambda : ',lambdas[best_index])\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.xlabel('lambdas')\n",
    "plt.ylabel('losses')\n",
    "plt.plot(lambdas, losses_te)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d01f9-d398-46bf-a830-81ee582b5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_initial = weights[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cca29c-7f97-4c2a-8626-826143acb9af",
   "metadata": {},
   "source": [
    "# 4- Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ab58a-a42b-49c3-a9f5-a40dda0985db",
   "metadata": {},
   "source": [
    "### a) With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438d5a-a1e2-4e12-926e-c9871f998c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nb_steps = 150\n",
    "gamma = 0.01\n",
    "\n",
    "for i in range(nb_steps):\n",
    "    w_final, loss= logistic_regression(y_train, x_train_final, w_initial, gamma)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de881a60-1aa4-42c3-91ea-c97470d9b960",
   "metadata": {},
   "source": [
    "### b) With Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029da5b-a2f8-4fe7-a716-72ccdd95d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nb_steps = 150\n",
    "gamma = 0.01\n",
    "\n",
    "for i in range(nb_steps):\n",
    "    w_final, loss= reg_logistic_regression(y_train, new_data, w_initial, gamma, lambda_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2e558-1ef7-4dfa-97eb-e64408732520",
   "metadata": {},
   "source": [
    "### c) With search of best hyperprameters lambda and gamma for ridge regression AND regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800c3cf-7beb-44b3-b011-4acdf01c9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_steps = 20\n",
    "lambdas = np.linspace(0,0.4,10)\n",
    "gammas = np.linspace(0,1,10)\n",
    "weights = np.zeros((len(lambdas),len(gammas), x_tr.shape[1]))\n",
    "losses_te = np.zeros((len(lambdas),len(gammas)))\n",
    "\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "    \n",
    "    for j, gamma in enumerate(gammas):\n",
    "        \n",
    "        w, _ = ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "        for step in range(nb_steps):\n",
    "\n",
    "            loss, w = reg_logistic_regression(y_tr, x_tr, w, gamma, lambda_)\n",
    "\n",
    "        weights[i,j] = w\n",
    "        loss_te = compute_loss(y_te, x_te, w)\n",
    "        losses_te[i][j] = loss_te           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03998a4-cfd7-4597-b2eb-aa29d988b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.unravel_index(np.argmin(losses_te), losses_te.shape)\n",
    "row_index, col_index = best_index\n",
    "best_weight = weights[row_index][col_index]\n",
    "print('Best lambda : ', lambdas[row_index])\n",
    "print('Best gamma : ', gammas[col_index])\n",
    "w_final = best_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068ed2d-2565-4d42-9fa5-cd502eb624b3",
   "metadata": {},
   "source": [
    "# 5- Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c87164-e3ee-4c75-836b-da0af573f56c",
   "metadata": {},
   "source": [
    "Prepare x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618c988-280f-435c-8afb-e181c30d8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[:,0:]\n",
    "\n",
    "#Remplacer les nan par la mediane de chaque colonne\n",
    "median = np.nanmedian(x_test, axis = 0)\n",
    "x_test_filled = x_test\n",
    "for col in range(x_test.shape[1]):\n",
    "    x_test_filled[:,col] = np.nan_to_num(x_test[:,col], nan= median[col])\n",
    "\n",
    "x_test_standardized, _ = standardize_(x_test_filled)\n",
    "\n",
    "#Enlever les colonnes qui ont une std = 0\n",
    "x_test_cleaned = x_test_standardized[:, col_to_keep]\n",
    "\n",
    "\n",
    "x_test_final = np.delete(x_test_cleaned, indices_correlated, axis = 1)\n",
    "\n",
    "print(x_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b61ae-5c47-433d-9e00-c0e81615e812",
   "metadata": {},
   "source": [
    "Finding y predicted with x_test and w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cac8ff-b249-433d-81d8-6baa10beaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_proba has the proba of each y to be 1 or -1\n",
    "y_pred_proba = sigmoid (np.dot(x_test_final, w_final))\n",
    "\n",
    "#If proba > 0.5, y becomes 1, else -1\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f399fdd-6c2c-47e4-b3bc-df4704f79d12",
   "metadata": {},
   "source": [
    "# 6- Creating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be853e81-56b4-433c-98c9-e20ea631a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'test_6.csv '\n",
    "create_csv_submission(test_ids, y_pred, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
