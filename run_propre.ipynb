{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5033210-8301-4857-a975-47dcb365e80a",
   "metadata": {},
   "source": [
    "Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7124d-c406-40d5-847b-d3e4d62b5379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155b57-1c16-48d9-bd82-e8a85d37af83",
   "metadata": {},
   "source": [
    "# 1- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca861ce-6071-4920-b488-e54af833ade7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('dataset_to_release/', sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d75f2-77b1-4b7b-837e-e6067b4e79b0",
   "metadata": {},
   "source": [
    "# 2- Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab30594-ae75-4183-980e-5d7b3c492c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check if duplicates in x_train\n",
    "duplicata(x_train)    \n",
    "\n",
    "#shuffle x_train and y_train at the same time to shuffle them in the same way\n",
    "x_train1, y_train1 = shuffle_rows (x_train, y_train)\n",
    "\n",
    "#check the distribution of sick and not sick\n",
    "test_balancy_dataset(y_train1)\n",
    "    \n",
    "#premiere colonne remplie de Nan (supprimer d autres des premieres colonnes)\n",
    "x_train1 = x_train1[:,9:]\n",
    "x_test1 = x_test[:,9:]\n",
    "\n",
    "#remplacer Nan par mediane (estce qu on a le droit de faire ca dans xtest? estce que cest une bonne idee ?)\n",
    "x_train1=nan_to_median(x_train1)\n",
    "x_test1=nan_to_median(x_test1)\n",
    "\n",
    "#enlever les lignes d outliers pour chaque colonne\n",
    "#x_train1, y_train1 = remove_outliers(x_train1, y_train1, threshold=0.000002)\n",
    "\n",
    "#standardization of test\n",
    "x_test1, _ = standardize_(x_test1)\n",
    "\n",
    "#enlever les colonnes qui ont une std nulle\n",
    "x_train1, col_to_keep=remove_zero_std_columns(x_train1)\n",
    "x_test1= x_test1[:, col_to_keep]\n",
    "\n",
    "#enlever les colonnes avec trop grande correlation\n",
    "x_train1, col_to_delete=remove_high_correlation_feature(x_train1)\n",
    "x_test1= np.delete(x_test1, col_to_delete, axis = 1)\n",
    "\n",
    "#enlever les lignes de outliers\n",
    "#x_train1, rows_to_keep =remove_outlier_rows(x_train1)\n",
    "\n",
    "#remplacer les outliers dans les colonnes qu'il reste avec la medianne aussi (le faire pour x_test?)\n",
    "#x_train1=replace_remaining_outlier_values(x_train1)\n",
    "#x_test1 = replace_remaining_outlier_values(x_test1)\n",
    "\n",
    "#Add a column of ones\n",
    "x_train1 = build_model_data(x_train1)\n",
    "x_test1 = build_model_data(x_test1)\n",
    "\n",
    "print('Finale shape of x_train : ', x_train1.shape)\n",
    "print('Finale shape of y_train : ', y_train1.shape)\n",
    "print('Finale shape of x_test : ', x_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9f636-a756-4ae1-ba1e-cd892fe54be5",
   "metadata": {},
   "source": [
    "### Dividing the dataset in balanced subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c439e1a-5221-4e92-b7d1-8321e3aca36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_ones = np.count_nonzero(y_train1 == 1)  #28 975 sick people in y_train\n",
    "nb_subsets = np.round( x_train.shape[0] / nb_ones, 0) #11 groups\n",
    "\n",
    "indices_ones = np.argwhere(y_train1 == 1)\n",
    "x_train_ones = x_train1[indices_ones]\n",
    "x_train_ones_ = np.squeeze(x_train_ones, axis=1)#Enleve une dimension en trop\n",
    "y_train_ones = y_train1[indices_ones]\n",
    "y_train_ones_ = np.squeeze(y_train_ones, axis = 1)\n",
    "\n",
    "indices_minus_ones = np.argwhere(y_train1 == -1)\n",
    "x_train_minus_ones = x_train1[indices_minus_ones]\n",
    "x_train_minus_ones_ = np.squeeze(x_train_minus_ones, axis=1) #Enleve une dimension en trop\n",
    "y_train_minus_ones = y_train1[indices_minus_ones]\n",
    "\n",
    "split_x_train_minus_ones = np.array_split(x_train_minus_ones, nb_subsets)  # 11 groups of 27 197 or 27 196 people\n",
    "split_y_train_minus_ones = np.array_split(y_train_minus_ones, nb_subsets)\n",
    "\n",
    "balanced_x_train = [] #List of 11 x_train\n",
    "balanced_y_train = [] #List of 11 y_train\n",
    "\n",
    "for i in range(len(split_x_train_minus_ones)):\n",
    "    together_x = np.concatenate((split_x_train_minus_ones[i], x_train_ones), axis=0)\n",
    "    together_x = np.squeeze(together_x, axis=1)\n",
    "    \n",
    "    together_y = np.concatenate((split_y_train_minus_ones[i], y_train_ones), axis = 0)\n",
    "    together_y = np.squeeze(together_y, axis=1)\n",
    "    \n",
    "    balanced_x_train.append(together_x) \n",
    "    balanced_y_train.append(together_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d8adb-546f-49e9-bae5-58ebf8b8e7fc",
   "metadata": {},
   "source": [
    "# 3- Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c5865-ab08-4031-8e4e-7edf78410871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, y_tr, x_te, y_te = split_data(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bba03-3861-468e-83c1-fc3f7995e305",
   "metadata": {},
   "source": [
    "#### With subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b339a-9a05-4dd6-bf66-79b2077d41aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_trs = []\n",
    "y_trs = []\n",
    "x_tes = []\n",
    "y_tes = []\n",
    "\n",
    "for i in range(len(balanced_x_train)):\n",
    "    x_tr, y_tr, x_te, y_te = split_data(balanced_x_train[i], balanced_y_train[i])\n",
    "    x_trs.append(x_tr)\n",
    "    y_trs.append(y_tr)\n",
    "    x_tes.append(x_te)\n",
    "    y_tes.append(y_te) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8cafbe-f1fa-4693-8e5a-a572837ba4a2",
   "metadata": {},
   "source": [
    "# 4- First step w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d91df4-1477-4a53-9227-ceb894641020",
   "metadata": {},
   "source": [
    "### a) Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7e430-7cef-4989-a8bb-2da861feca90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#No hyperparameters needed!\n",
    "w_initial, loss = least_squares(y_tr, x_tr)\n",
    "print('Loss with x_tr : ', loss)\n",
    "print('Loss with x_te : ', compute_loss(y_te, x_te, w_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfded2e-7df7-43f0-abef-052391e5a38d",
   "metadata": {},
   "source": [
    "With subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132869b-4540-492a-9ace-45ca41a1c854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "losses = []\n",
    "\n",
    "for i in range(len(balanced_x_train)):\n",
    "    w,_ = least_squares(y_trs[i], x_trs[i])\n",
    "    weights.append(w)\n",
    "    loss = compute_loss(y_tes[i], x_tes[i], w)\n",
    "    losses.append(loss)\n",
    "    \n",
    "w_initial = np.mean(weights, axis = 0)\n",
    "loss = compute_loss(y_te, x_te, w_initial)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf41ded-2ebf-4460-9326-ae88fdaefa7c",
   "metadata": {},
   "source": [
    "### b) Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7027536-ff7f-4c71-a940-a49b8c2ba4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#With fixed hyperparameters\n",
    "lambda_ = 0.001\n",
    "w_initial, loss = ridge_regression(y_tr, x_tr, lambda_)\n",
    "print('Loss with x_tr : ', loss)\n",
    "print('Loss with x_te : ', compute_loss(y_te, x_te, w_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863bac2-5ce6-4e3c-9f9f-6ca400ca8c5f",
   "metadata": {},
   "source": [
    "##### Looking for good hyperparameters  lambda_ for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469777b-5281-406d-a29f-2f4b4cc46ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#VERSION 1\n",
    "lambdas = np.linspace(0.000001,0.001,50)\n",
    "weights = []\n",
    "losses_te = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    w,_ = ridge_regression(y_tr, x_tr, lambda_)\n",
    "    weights.append(w)\n",
    "    loss = compute_loss(y_te, x_te, w)\n",
    "    losses_te.append(loss)\n",
    "\n",
    "best_index = losses_te.index(min(losses_te))\n",
    "print('Smallest loss : ',losses_te[best_index])\n",
    "print('Best lambda : ',lambdas[best_index])\n",
    "w_initial = weights[best_index]\n",
    "\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.xlabel('lambdas')\n",
    "plt.ylabel('losses')\n",
    "plt.plot(lambdas, losses_te)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e586c8-0b84-4bc6-9ab4-095fb7f701d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#VERSION 2\n",
    "k_fold = 3\n",
    "lambdas = np.linspace(0,0.4,10)\n",
    "best_lambda, best_acc = cross_validation_best_lambda_ridge(y_train1, x_train1, k_fold, lambdas)\n",
    "print(best_lambda)\n",
    "w_initial ,_ = ridge_regression(y_train1, x_train1, best_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab192bd9-3fdf-4994-b501-e78753379b8f",
   "metadata": {},
   "source": [
    "With subsets and fixed lambda :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72133589-9877-4839-b672-8838a39461c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "losses = []\n",
    "lambda_ = 0.01\n",
    "\n",
    "for i in range(len(balanced_x_train)):\n",
    "    w,_ = ridge_regression(y_trs[i], x_trs[i], lambda_)\n",
    "    weights.append(w)\n",
    "    loss = compute_loss(y_tes[i], x_tes[i], w)\n",
    "    losses.append(loss)\n",
    "    \n",
    "w_initial = np.mean(weights, axis = 0)\n",
    "print('Mean loss with the training sets : ', np.mean(losses))\n",
    "loss = compute_loss(y_te, x_te, w_initial)\n",
    "print('Loss with test set : ',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437980fe-7149-42d7-a992-9e0446553b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5 - Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c39d1-d170-482a-81af-69f12a0d394a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### a) Mean squared error gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b567a-70ce-4164-8347-73f75c5d34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With fixed hyperparamaters\n",
    "max_iters = 10\n",
    "gamma = 0.1\n",
    "w_final, loss = mean_squared_error_gd(y_train1, x_train1, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649b72d-aebf-4ea9-934f-366b8360d55f",
   "metadata": {},
   "source": [
    "##### Search of best hyperparameter gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785480c2-8d06-4934-983a-395a954159f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_te = []\n",
    "weights = []\n",
    "max_iters = 10\n",
    "gammas = np.linspace(0,1,10)\n",
    "\n",
    "for gamma in gammas :\n",
    "    w_final, loss = mean_squared_error_gd(y_tr, x_tr, w_initial, max_iters, gamma)\n",
    "    weights.append(w_final)\n",
    "    losses_te.append(compute_loss(y_te, x_te, w_final))\n",
    "    w_initial = w_final\n",
    "\n",
    "best_index = losses_te.index(min(losses_te))\n",
    "print('Best gamma : ', gammas[best_index])\n",
    "print('Smallest loss : ', losses_te[best_index])\n",
    "w_final = weights[best_index]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe5554-c1e7-4b95-9271-c0463f290b16",
   "metadata": {},
   "source": [
    "### b) Mean squared error stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2d399-4751-46c4-afbf-6a9530fcbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With fixed hyperparameters\n",
    "max_iters = 10\n",
    "gamma = 0.1\n",
    "batch_size = 2000\n",
    "w_final, loss = mean_squared_error_sgd(y_train1, x_train1, w_initial, batch_size, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6603584-c818-472b-867e-fbc96e4df0e2",
   "metadata": {},
   "source": [
    "##### Search of best hyperparameter gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f952a-bd37-4ad3-98a9-fad6489747b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_te = []\n",
    "weights = []\n",
    "max_iters = 10\n",
    "batch_size = 2000\n",
    "gammas = np.linspace(0,1,10)\n",
    "\n",
    "for gamma in gammas :\n",
    "    w_final, loss = mean_squared_error_sgd(y_tr, x_tr, w_initial, max_iters, gamma)\n",
    "    weights.append(w_final)\n",
    "    losses_te.append(compute_loss(y_te, x_te, w_final))\n",
    "    w_initial = w_final\n",
    "\n",
    "best_index = losses_te.index(min(losses_te))\n",
    "print('Best gamma : ', gammas[best_index])\n",
    "print('Smallest loss : ', losses_te[best_index])\n",
    "w_final = weights[best_index]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb5756-4fe5-48a3-9336-1d13d38d8ed9",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37faa05-30b2-4155-b871-11ac2c6d795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With fixed hyperparameters\n",
    "nb_steps = 150\n",
    "gamma = 0.01\n",
    "\n",
    "for i in range(nb_steps):\n",
    "    w_final, loss= logistic_regression(y_train, x_train_final, w_initial, gamma)\n",
    "    w_initial = w_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6913e-482c-4d84-b794-afe61920064a",
   "metadata": {},
   "source": [
    "##### Search of best hyperparameter gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ba15d-3a87-4492-b0b4-8fbcab3d4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_te = []\n",
    "weights = []\n",
    "nb_steps = 150\n",
    "batch_size = 2000\n",
    "gammas = np.linspace(0,1,10)\n",
    "\n",
    "for gamma in gammas :\n",
    "    for i in range(nb_steps):\n",
    "        w_final, loss = logistic_regression(y_tr, x_tr, w_initial, gamma)\n",
    "        w_initial = w_final\n",
    "    weights.append(w_final)\n",
    "    losses_te.append(compute_loss(y_te, x_te, w_final))\n",
    "    w_initial = w_final\n",
    "\n",
    "best_index = losses_te.index(min(losses_te))\n",
    "print('Best gamma : ', gammas[best_index])\n",
    "print('Smallest loss : ', losses_te[best_index])\n",
    "w_final = weights[best_index]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de881a60-1aa4-42c3-91ea-c97470d9b960",
   "metadata": {},
   "source": [
    "### c) Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029da5b-a2f8-4fe7-a716-72ccdd95d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_steps = 150\n",
    "gamma = 0.01\n",
    "\n",
    "for i in range(nb_steps):\n",
    "    w_final, loss= reg_logistic_regression(y_train, new_data, w_initial, gamma, lambda_)\n",
    "    w_initial = w_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2e558-1ef7-4dfa-97eb-e64408732520",
   "metadata": {},
   "source": [
    "##### Search of best hyperprameters lambda and gamma for ridge regression AND regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800c3cf-7beb-44b3-b011-4acdf01c9140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_steps = 20\n",
    "lambdas = np.linspace(0,0.4,10)\n",
    "gammas = np.linspace(0,1,10)\n",
    "weights = np.zeros((len(lambdas),len(gammas), x_tr.shape[1]))\n",
    "losses_te = np.zeros((len(lambdas),len(gammas)))\n",
    "\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        \n",
    "        w, _ = ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "        for step in range(nb_steps):\n",
    "\n",
    "            w, loss = reg_logistic_regression(y_tr, x_tr, w, gamma, lambda_)\n",
    "\n",
    "        weights[i,j] = w\n",
    "        loss_te = compute_loss(y_te, x_te, w)\n",
    "        losses_te[i][j] = loss_te   \n",
    "\n",
    "best_index = np.unravel_index(np.argmin(losses_te), losses_te.shape)\n",
    "row_index, col_index = best_index\n",
    "best_weight = weights[row_index][col_index]\n",
    "print('Best lambda : ', lambdas[row_index])\n",
    "print('Best gamma : ', gammas[col_index])\n",
    "print('Smallest loss : ', losses_te[best_index])\n",
    "w_final = best_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068ed2d-2565-4d42-9fa5-cd502eb624b3",
   "metadata": {},
   "source": [
    "# 6 - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b61ae-5c47-433d-9e00-c0e81615e812",
   "metadata": {},
   "source": [
    "Finding y predicted with x_test and w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cac8ff-b249-433d-81d8-6baa10beaec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#After a gradient algorithm\n",
    "y_pred = sigmoid_prediction(x_test1, w_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af1363-d4f5-43dc-8c67-16dc5e3f0e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Without gradient algorithm\n",
    "y_pred = sigmoid_prediction(x_test1, w_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f399fdd-6c2c-47e4-b3bc-df4704f79d12",
   "metadata": {},
   "source": [
    "# 7 - Creating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be853e81-56b4-433c-98c9-e20ea631a505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'test_12.csv '\n",
    "create_csv_submission(test_ids, y_pred, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee0416-b743-4436-9d0e-8d14f2899d46",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### idees\n",
    "- faire extension polynomiale (si on enleve bcp de colonnes grace aux outliers ca prend peutetre pas trop de temps)\n",
    "- sortir les outliers du dataset\n",
    "- enlever les colonnes avec trop de nan ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b354f2-0d40-44eb-811e-27b92aaffe70",
   "metadata": {},
   "source": [
    "### Fonctions utiles pour améliorer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86ee75-8f98-440b-85a3-092c30b42556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fonctions utiles pour améliorer le modèle\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    poly=np.zeros((x.shape[0], degree+1))\n",
    "    for i in range (x.shape[0]):\n",
    "        for j in range (degree+1):\n",
    "            poly[i, j]=x[i]**j\n",
    "    return poly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
